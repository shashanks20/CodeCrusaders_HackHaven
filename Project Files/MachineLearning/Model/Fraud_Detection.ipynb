{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Data Collection and Preprocessing**"
      ],
      "metadata": {
        "id": "m1Z3s9abEx57"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from scipy import sparse\n",
        "from geopy.distance import geodesic\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n"
      ],
      "metadata": {
        "id": "sjDEaC33WvOn"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = pd.read_csv(\"fraudTrain.csv\")\n",
        "test_data = pd.read_csv(\"fraudTest.csv\")\n",
        "\n",
        "\n",
        "train_data = train_data.dropna()\n",
        "\n",
        "test_data = test_data.dropna()\n",
        "\n",
        "cat_features = ['merchant', 'category', 'gender', 'city', 'state', 'job']\n",
        "\n",
        "encoder = OneHotEncoder(handle_unknown='ignore')\n",
        "encoded_train_data = encoder.fit_transform(train_data[cat_features])\n",
        "\n",
        "encoded_test_data = encoder.transform(test_data[cat_features])\n",
        "\n",
        "num_features = ['amt', 'lat', 'long', 'city_pop', 'unix_time', 'merch_lat', 'merch_long']\n",
        "\n"
      ],
      "metadata": {
        "id": "os2QGNAPa94e"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Feature Engineering**"
      ],
      "metadata": {
        "id": "67fvKvO7E5HR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature Engineering to add new columns for train data\n",
        "num_features = ['amt', 'lat', 'long', 'city_pop', 'unix_time', 'merch_lat', 'merch_long']\n",
        "transaction_frequency = train_data.groupby('cc_num').size()\n",
        "train_data['transaction_frequency'] = train_data['cc_num'].map(transaction_frequency)\n",
        "train_data['trans_date_trans_time'] = pd.to_datetime(train_data['trans_date_trans_time'])\n",
        "train_data = train_data.sort_values(by=['cc_num', 'trans_date_trans_time'])\n",
        "train_data['time_since_last_transaction'] = train_data.groupby('cc_num')['trans_date_trans_time'].diff().dt.total_seconds().fillna(0)\n",
        "train_data['distance_customer_merchant'] = train_data.apply(lambda row: geodesic((row['lat'], row['long']), (row['merch_lat'], row['merch_long'])).miles, axis=1)\n",
        "combined_train_data = sparse.hstack([encoded_train_data, train_data[num_features]])"
      ],
      "metadata": {
        "id": "0C-WU3D4F93V"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature Engineering to add new columns for test data\n",
        "transaction_frequency_test = test_data.groupby('cc_num').size()\n",
        "test_data['transaction_frequency'] = test_data['cc_num'].map(transaction_frequency_test)\n",
        "test_data['trans_date_trans_time'] = pd.to_datetime(test_data['trans_date_trans_time'])\n",
        "test_data = test_data.sort_values(by=['cc_num', 'trans_date_trans_time'])\n",
        "test_data['time_since_last_transaction'] = test_data.groupby('cc_num')['trans_date_trans_time'].diff().dt.total_seconds().fillna(0)\n",
        "test_data['distance_customer_merchant'] = test_data.apply(lambda row: geodesic((row['lat'], row['long']), (row['merch_lat'], row['merch_long'])).miles, axis=1)\n",
        "combined_test_data = sparse.hstack([encoded_test_data, test_data[num_features]])"
      ],
      "metadata": {
        "id": "0c_EIH2lGSgV"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Synthetic Minority Over-sampling Technique (SMOTE) For resampling the data to balance the classes**"
      ],
      "metadata": {
        "id": "w2s1eUc7FYbZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE"
      ],
      "metadata": {
        "id": "S07I338ICJQt"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Resampling of train Data\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled_train, y_resampled_train = smote.fit_resample(combined_train_data, train_data['is_fraud'])\n",
        "\n",
        "# Resampling of test Data\n",
        "X_resampled_test, y_resampled_test = smote.fit_resample(combined_test_data, test_data['is_fraud'])\n",
        "\n",
        "\n",
        "scaler_train = StandardScaler(with_mean=False)\n",
        "scaled_train_data = scaler_train.fit_transform(X_resampled_train)\n",
        "\n",
        "\n",
        "scaler_test = StandardScaler(with_mean=False)\n",
        "scaled_test_data = scaler_test.fit_transform(X_resampled_test)"
      ],
      "metadata": {
        "id": "2Fh99m7vtYkP"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Machine Learning Models**"
      ],
      "metadata": {
        "id": "E_aVMqsAGA7G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC"
      ],
      "metadata": {
        "id": "LptwJ1PjBrR6"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ensemble Learning**"
      ],
      "metadata": {
        "id": "a-H_xsl8GKqh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ensemble_models = {\n",
        "     \"LogisticRegression\": LogisticRegression(max_iter=1000, random_state=42),\n",
        "    \"RandomForest\": RandomForestClassifier(random_state=42),\n",
        "    \"GradientBoosting\": GradientBoostingClassifier(random_state=42),\n",
        "}"
      ],
      "metadata": {
        "id": "TIBarOwgwBM1"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for name, model in ensemble_models.items():\n",
        "    model.fit(X_resampled_train, y_resampled_train)"
      ],
      "metadata": {
        "id": "r0TUorklE5KQ"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score, precision_score, recall_score ,accuracy_score"
      ],
      "metadata": {
        "id": "dPdg1kO4GWHO"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation_metrics = {}\n",
        "\n",
        "for name, model in ensemble_models.items():\n",
        "\n",
        "    y_pred = model.predict(X_resampled_test)\n",
        "    accuracy = accuracy_score(y_resampled_test, y_pred)\n",
        "    precision = precision_score(y_resampled_test, y_pred)\n",
        "    recall = recall_score(y_resampled_test, y_pred)\n",
        "    f1 = f1_score(y_resampled_test, y_pred)\n",
        "\n",
        "    evaluation_metrics[name] = {\n",
        "        \"Accuracy\": accuracy,\n",
        "        \"Precision\": precision,\n",
        "        \"Recall\": recall,\n",
        "        \"F1 Score\": f1\n",
        "    }\n",
        "\n",
        "for name, metrics in evaluation_metrics.items():\n",
        "    print(f\"Model: {name}\")\n",
        "    print(f\"Accuracy: {metrics['Accuracy']}\")\n",
        "    print(f\"Precision: {metrics['Precision']}\")\n",
        "    print(f\"Recall: {metrics['Recall']}\")\n",
        "    print(f\"F1 Score: {metrics['F1 Score']}\")\n",
        "    print()"
      ],
      "metadata": {
        "id": "TCWZoVauHqNu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "517bf782-6eca-442a-e180-2ff738d3ac78"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: LogisticRegression\n",
            "Accuracy: 0.5\n",
            "Precision: 0.0\n",
            "Recall: 0.0\n",
            "F1 Score: 0.0\n",
            "\n",
            "Model: RandomForest\n",
            "Accuracy: 0.9663882741053159\n",
            "Precision: 1.0\n",
            "Recall: 0.9327765482106318\n",
            "F1 Score: 0.9652192324810627\n",
            "\n",
            "Model: GradientBoosting\n",
            "Accuracy: 0.9711988975654571\n",
            "Precision: 0.9781271186440678\n",
            "Recall: 0.9639537311563035\n",
            "F1 Score: 0.9709887059120449\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Save the models**\n"
      ],
      "metadata": {
        "id": "Ek86Mpl0Gge6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "for name, model in ensemble_models.items():\n",
        "    with open(f'{name}_model.pkl', 'wb') as file:\n",
        "        pickle.dump(model, file)"
      ],
      "metadata": {
        "id": "HhTs6-XrnBDZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Deep learning models**"
      ],
      "metadata": {
        "id": "IrtsJCzyGpQs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, LSTM"
      ],
      "metadata": {
        "id": "d2_KAgXaB7on"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Convolutional Neural Networks (CNNs) or Recurrent Neural Networks (RNNs)**"
      ],
      "metadata": {
        "id": "p0h8INbEHEze"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CNN\n",
        "model_cnn = Sequential()\n",
        "model_cnn.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X_resampled_train.shape[1], 1)))\n",
        "model_cnn.add(MaxPooling1D(pool_size=2))\n",
        "model_cnn.add(Flatten())\n",
        "model_cnn.add(Dense(50, activation='relu'))\n",
        "model_cnn.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the CNN model\n",
        "model_cnn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Reshape the data for CNN\n",
        "if sparse.issparse(X_resampled_train):\n",
        "    X_train_reshaped_cnn = X_resampled_train.toarray().reshape((X_resampled_train.shape[0], X_resampled_train.shape[1], 1))\n",
        "else:\n",
        "    X_train_reshaped_cnn = X_resampled_train.reshape((X_resampled_train.shape[0], X_resampled_train.shape[1], 1))\n",
        "\n",
        "model_cnn.fit(X_train_reshaped_cnn, y_resampled_train, epochs=10, batch_size=32)"
      ],
      "metadata": {
        "id": "D6xoli-XMIfv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e00f365e-811e-43c9-9878-7bc643b35861"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "486/486 [==============================] - 6s 6ms/step - loss: 259202.4531 - accuracy: 0.5001\n",
            "Epoch 2/10\n",
            "486/486 [==============================] - 3s 6ms/step - loss: 0.6932 - accuracy: 0.4983\n",
            "Epoch 3/10\n",
            "486/486 [==============================] - 3s 5ms/step - loss: 0.6932 - accuracy: 0.4927\n",
            "Epoch 4/10\n",
            "486/486 [==============================] - 3s 5ms/step - loss: 0.6932 - accuracy: 0.4991\n",
            "Epoch 5/10\n",
            "486/486 [==============================] - 3s 5ms/step - loss: 0.6932 - accuracy: 0.4946\n",
            "Epoch 6/10\n",
            "486/486 [==============================] - 3s 6ms/step - loss: 0.6932 - accuracy: 0.4961\n",
            "Epoch 7/10\n",
            "486/486 [==============================] - 3s 6ms/step - loss: 0.6932 - accuracy: 0.4959\n",
            "Epoch 8/10\n",
            "486/486 [==============================] - 3s 5ms/step - loss: 0.6932 - accuracy: 0.4979\n",
            "Epoch 9/10\n",
            "486/486 [==============================] - 3s 5ms/step - loss: 0.6932 - accuracy: 0.4977\n",
            "Epoch 10/10\n",
            "486/486 [==============================] - 3s 5ms/step - loss: 0.6932 - accuracy: 0.4996\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7b7f21113b50>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# RNN\n",
        "model_rnn = Sequential()\n",
        "model_rnn.add(LSTM(50, input_shape=(X_resampled_train.shape[1], 1)))\n",
        "model_rnn.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the RNN model\n",
        "model_rnn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Reshape the data for RNN\n",
        "if sparse.issparse(X_resampled_train):\n",
        "    X_train_reshaped_rnn = X_resampled_train.toarray().reshape((X_resampled_train.shape[0], X_resampled_train.shape[1], 1))\n",
        "else:\n",
        "    X_train_reshaped_rnn = X_resampled_train.reshape((X_resampled_train.shape[0], X_resampled_train.shape[1], 1))\n",
        "\n",
        "model_rnn.fit(X_train_reshaped_rnn, y_resampled_train, epochs=10, batch_size=32)"
      ],
      "metadata": {
        "id": "kldMTKXRDlz1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "266b534a-7eb7-465c-ac8b-a83a093824a7"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "486/486 [==============================] - 28s 54ms/step - loss: 0.4074 - accuracy: 0.8180\n",
            "Epoch 2/10\n",
            "486/486 [==============================] - 26s 53ms/step - loss: 0.1960 - accuracy: 0.9374\n",
            "Epoch 3/10\n",
            "486/486 [==============================] - 26s 54ms/step - loss: 0.1841 - accuracy: 0.9402\n",
            "Epoch 4/10\n",
            "486/486 [==============================] - 26s 54ms/step - loss: 0.1772 - accuracy: 0.9425\n",
            "Epoch 5/10\n",
            "486/486 [==============================] - 27s 55ms/step - loss: 0.1692 - accuracy: 0.9449\n",
            "Epoch 6/10\n",
            "486/486 [==============================] - 26s 54ms/step - loss: 0.1636 - accuracy: 0.9472\n",
            "Epoch 7/10\n",
            "486/486 [==============================] - 27s 55ms/step - loss: 0.1623 - accuracy: 0.9473\n",
            "Epoch 8/10\n",
            "486/486 [==============================] - 27s 55ms/step - loss: 0.1615 - accuracy: 0.9484\n",
            "Epoch 9/10\n",
            "486/486 [==============================] - 27s 55ms/step - loss: 0.1575 - accuracy: 0.9503\n",
            "Epoch 10/10\n",
            "486/486 [==============================] - 27s 55ms/step - loss: 0.1528 - accuracy: 0.9515\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7b7ebc148b80>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X_resampled_test_dense = X_resampled_test.toarray()\n",
        "\n",
        "# Reshape the test data for CNN & RNN\n",
        "X_resampled_test_reshaped = X_resampled_test_dense.reshape((X_resampled_test_dense.shape[0], X_resampled_test_dense.shape[1], 1))\n",
        "\n",
        "y_pred_cnn = model_cnn.predict(X_resampled_test_reshaped)\n",
        "\n",
        "# Convert probabilities to binary predictions (0 or 1)\n",
        "y_pred_cnn_binary = (y_pred_cnn > 0.5).astype(int)\n",
        "\n",
        "accuracy_cnn = accuracy_score(y_resampled_test, y_pred_cnn_binary)\n",
        "precision_cnn = precision_score(y_resampled_test, y_pred_cnn_binary)\n",
        "recall_cnn = recall_score(y_resampled_test, y_pred_cnn_binary)\n",
        "f1_cnn = f1_score(y_resampled_test, y_pred_cnn_binary)\n",
        "\n",
        "print(\"CNN Model Metrics:\")\n",
        "print(\"Accuracy:\", accuracy_cnn)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "T7UQ4qx4QckM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6db8a521-7527-4212-e4a6-cb2577061430"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "730/730 [==============================] - 2s 2ms/step\n",
            "CNN Model Metrics:\n",
            "Accuracy: 0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_rnn = model_rnn.predict(X_resampled_test_reshaped)\n",
        "\n",
        "# Convert probabilities to binary predictions (0 or 1)\n",
        "y_pred_rnn_binary = (y_pred_rnn > 0.5).astype(int)\n",
        "\n",
        "accuracy_rnn = accuracy_score(y_resampled_test, y_pred_rnn_binary)\n",
        "precision_rnn = precision_score(y_resampled_test, y_pred_rnn_binary)\n",
        "recall_rnn = recall_score(y_resampled_test, y_pred_rnn_binary)\n",
        "f1_rnn = f1_score(y_resampled_test, y_pred_rnn_binary)\n",
        "\n",
        "print(\"\\nRNN Model Metrics:\")\n",
        "print(\"Accuracy:\", accuracy_rnn)"
      ],
      "metadata": {
        "id": "ypTCRyxqEFT6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4de3aeb9-6ca6-40dd-b1e5-258372ac19d4"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "730/730 [==============================] - 20s 27ms/step\n",
            "\n",
            "RNN Model Metrics:\n",
            "Accuracy: 0.8351332819062313\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Save the models**\n"
      ],
      "metadata": {
        "id": "Du2E9tgfGk50"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle"
      ],
      "metadata": {
        "id": "eunA14dSANZP"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('cnn_model.pkl', 'wb') as file:\n",
        "    pickle.dump(model_cnn, file)"
      ],
      "metadata": {
        "id": "fFZ_CO5iPGbO"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('rnn_model.pkl', 'wb') as file:\n",
        "    pickle.dump(model_rnn, file)"
      ],
      "metadata": {
        "id": "rHA3A0FNogub"
      },
      "execution_count": 20,
      "outputs": []
    }
  ]
}