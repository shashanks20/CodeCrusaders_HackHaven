{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from scipy import sparse\n",
        "from geopy.distance import geodesic\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score ,accuracy_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, LSTM"
      ],
      "metadata": {
        "id": "sjDEaC33WvOn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = pd.read_csv(\"fraudTrain.csv\")\n",
        "test_data = pd.read_csv(\"fraudTest.csv\")\n",
        "\n",
        "# Handle missing values in training data (if any)\n",
        "train_data = train_data.dropna()\n",
        "\n",
        "# Handle missing values in test data (if any)\n",
        "test_data = test_data.dropna()\n",
        "\n",
        "cat_features = ['merchant', 'category', 'gender', 'city', 'state', 'job']\n",
        "\n",
        "# One-hot encode categorical features for training data\n",
        "encoder = OneHotEncoder(handle_unknown='ignore')\n",
        "encoded_train_data = encoder.fit_transform(train_data[cat_features])\n",
        "\n",
        "# One-hot encode categorical features for test data\n",
        "encoded_test_data = encoder.transform(test_data[cat_features])\n",
        "\n",
        "num_features = ['amt', 'lat', 'long', 'city_pop', 'unix_time', 'merch_lat', 'merch_long']\n",
        "\n"
      ],
      "metadata": {
        "id": "os2QGNAPa94e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine encoded categorical features with numerical features for training data\n",
        "num_features = ['amt', 'lat', 'long', 'city_pop', 'unix_time', 'merch_lat', 'merch_long']\n",
        "transaction_frequency = train_data.groupby('cc_num').size()\n",
        "train_data['transaction_frequency'] = train_data['cc_num'].map(transaction_frequency)\n",
        "train_data['trans_date_trans_time'] = pd.to_datetime(train_data['trans_date_trans_time'])\n",
        "train_data = train_data.sort_values(by=['cc_num', 'trans_date_trans_time'])\n",
        "train_data['time_since_last_transaction'] = train_data.groupby('cc_num')['trans_date_trans_time'].diff().dt.total_seconds().fillna(0)\n",
        "train_data['distance_customer_merchant'] = train_data.apply(lambda row: geodesic((row['lat'], row['long']), (row['merch_lat'], row['merch_long'])).miles, axis=1)\n",
        "combined_train_data = sparse.hstack([encoded_train_data, train_data[num_features]])"
      ],
      "metadata": {
        "id": "0C-WU3D4F93V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transaction_frequency_test = test_data.groupby('cc_num').size()\n",
        "test_data['transaction_frequency'] = test_data['cc_num'].map(transaction_frequency_test)\n",
        "test_data['trans_date_trans_time'] = pd.to_datetime(test_data['trans_date_trans_time'])\n",
        "test_data = test_data.sort_values(by=['cc_num', 'trans_date_trans_time'])\n",
        "test_data['time_since_last_transaction'] = test_data.groupby('cc_num')['trans_date_trans_time'].diff().dt.total_seconds().fillna(0)\n",
        "test_data['distance_customer_merchant'] = test_data.apply(lambda row: geodesic((row['lat'], row['long']), (row['merch_lat'], row['merch_long'])).miles, axis=1)\n",
        "combined_test_data = sparse.hstack([encoded_test_data, test_data[num_features]])"
      ],
      "metadata": {
        "id": "0c_EIH2lGSgV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Resample the training data using SMOTE\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled_train, y_resampled_train = smote.fit_resample(combined_train_data, train_data['is_fraud'])\n",
        "\n",
        "# Resample the test data using SMOTE\n",
        "X_resampled_test, y_resampled_test = smote.fit_resample(combined_test_data, test_data['is_fraud'])\n",
        "\n",
        "# Standardize numerical features for training data\n",
        "scaler_train = StandardScaler(with_mean=False)\n",
        "scaled_train_data = scaler_train.fit_transform(X_resampled_train)\n",
        "\n",
        "# Standardize numerical features for test data\n",
        "scaler_test = StandardScaler(with_mean=False)\n",
        "scaled_test_data = scaler_test.fit_transform(X_resampled_test)"
      ],
      "metadata": {
        "id": "2Fh99m7vtYkP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ensemble_models = {\n",
        "     \"LogisticRegression\": LogisticRegression(max_iter=1000, random_state=42),\n",
        "    \"DecisionTree\": DecisionTreeClassifier(random_state=42),\n",
        "    \"RandomForest\": RandomForestClassifier(random_state=42),\n",
        "    \"GradientBoosting\": GradientBoostingClassifier(random_state=42),\n",
        "    \"AdaBoost\": AdaBoostClassifier(random_state=42),\n",
        "    \"SupportVectorMachine\": SVC(random_state=42)\n",
        "}"
      ],
      "metadata": {
        "id": "TIBarOwgwBM1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for name, model in ensemble_models.items():\n",
        "    # Fit the model\n",
        "    model.fit(X_resampled_train, y_resampled_train)"
      ],
      "metadata": {
        "id": "r0TUorklE5KQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dictionary to store evaluation metrics for each model\n",
        "evaluation_metrics = {}\n",
        "\n",
        "# Evaluate each model\n",
        "for name, model in ensemble_models.items():\n",
        "    # Make predictions on the test data\n",
        "    y_pred = model.predict(X_resampled_test)\n",
        "\n",
        "    # Calculate evaluation metrics\n",
        "    accuracy = accuracy_score(y_resampled_test, y_pred)\n",
        "    precision = precision_score(y_resampled_test, y_pred)\n",
        "    recall = recall_score(y_resampled_test, y_pred)\n",
        "    f1 = f1_score(y_resampled_test, y_pred)\n",
        "\n",
        "    # Store evaluation metrics in the dictionary\n",
        "    evaluation_metrics[name] = {\n",
        "        \"Accuracy\": accuracy,\n",
        "        \"Precision\": precision,\n",
        "        \"Recall\": recall,\n",
        "        \"F1 Score\": f1\n",
        "    }\n",
        "\n",
        "# Print evaluation metrics for each model\n",
        "for name, metrics in evaluation_metrics.items():\n",
        "    print(f\"Model: {name}\")\n",
        "    print(f\"Accuracy: {metrics['Accuracy']}\")\n",
        "    print(f\"Precision: {metrics['Precision']}\")\n",
        "    print(f\"Recall: {metrics['Recall']}\")\n",
        "    print(f\"F1 Score: {metrics['F1 Score']}\")\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TCWZoVauHqNu",
        "outputId": "347118a9-5f91-48ff-e5ff-07912276b326"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: LogisticRegression\n",
            "Accuracy: 0.5\n",
            "Precision: 0.5\n",
            "Recall: 1.0\n",
            "F1 Score: 0.6666666666666666\n",
            "\n",
            "Model: DecisionTree\n",
            "Accuracy: 0.7518668726664092\n",
            "Precision: 0.9860852279786309\n",
            "Recall: 0.5109437363203296\n",
            "F1 Score: 0.6731119874485859\n",
            "\n",
            "Model: RandomForest\n",
            "Accuracy: 0.6371185786017768\n",
            "Precision: 1.0\n",
            "Recall: 0.2742371572035535\n",
            "F1 Score: 0.4304334646862686\n",
            "\n",
            "Model: GradientBoosting\n",
            "Accuracy: 0.9369125788592765\n",
            "Precision: 0.9785643773797772\n",
            "Recall: 0.8933951332560834\n",
            "F1 Score: 0.9340422667923005\n",
            "\n",
            "Model: AdaBoost\n",
            "Accuracy: 0.8623986095017381\n",
            "Precision: 0.945054945054945\n",
            "Recall: 0.7695377880777649\n",
            "F1 Score: 0.8483128126885001\n",
            "\n",
            "Model: SupportVectorMachine\n",
            "Accuracy: 0.5\n",
            "Precision: 0.5\n",
            "Recall: 1.0\n",
            "F1 Score: 0.6666666666666666\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example of CNN\n",
        "model_cnn = Sequential()\n",
        "model_cnn.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X_resampled_train.shape[1], 1)))\n",
        "model_cnn.add(MaxPooling1D(pool_size=2))\n",
        "model_cnn.add(Flatten())\n",
        "model_cnn.add(Dense(50, activation='relu'))\n",
        "model_cnn.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Example of RNN (LSTM)\n",
        "model_rnn = Sequential()\n",
        "model_rnn.add(LSTM(50, input_shape=(X_resampled_train.shape[1], 1)))\n",
        "model_rnn.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile and fit the CNN model\n",
        "model_cnn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Reshape the data for CNN\n",
        "if sparse.issparse(X_resampled_train):\n",
        "    X_train_reshaped_cnn = X_resampled_train.toarray().reshape((X_resampled_train.shape[0], X_resampled_train.shape[1], 1))\n",
        "else:\n",
        "    X_train_reshaped_cnn = X_resampled_train.reshape((X_resampled_train.shape[0], X_resampled_train.shape[1], 1))\n",
        "\n",
        "model_cnn.fit(X_train_reshaped_cnn, y_resampled_train, epochs=10, batch_size=32)\n",
        "\n",
        "# Compile and fit the RNN model\n",
        "model_rnn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Reshape the data for RNN\n",
        "if sparse.issparse(X_resampled_train):\n",
        "    X_train_reshaped_rnn = X_resampled_train.toarray().reshape((X_resampled_train.shape[0], X_resampled_train.shape[1], 1))\n",
        "else:\n",
        "    X_train_reshaped_rnn = X_resampled_train.reshape((X_resampled_train.shape[0], X_resampled_train.shape[1], 1))\n",
        "\n",
        "model_rnn.fit(X_train_reshaped_rnn, y_resampled_train, epochs=10, batch_size=32)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D6xoli-XMIfv",
        "outputId": "b76705a5-af68-4a0c-e4aa-8e5923c5c510"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "969/969 [==============================] - 7s 6ms/step - loss: 50894.5977 - accuracy: 0.5003\n",
            "Epoch 2/10\n",
            "969/969 [==============================] - 6s 6ms/step - loss: 0.6932 - accuracy: 0.4986\n",
            "Epoch 3/10\n",
            "969/969 [==============================] - 6s 6ms/step - loss: 0.6932 - accuracy: 0.4978\n",
            "Epoch 4/10\n",
            "969/969 [==============================] - 6s 6ms/step - loss: 0.6932 - accuracy: 0.4982\n",
            "Epoch 5/10\n",
            "969/969 [==============================] - 6s 6ms/step - loss: 0.6932 - accuracy: 0.5010\n",
            "Epoch 6/10\n",
            "969/969 [==============================] - 6s 6ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 7/10\n",
            "969/969 [==============================] - 6s 6ms/step - loss: 0.6932 - accuracy: 0.4985\n",
            "Epoch 8/10\n",
            "969/969 [==============================] - 6s 6ms/step - loss: 0.6932 - accuracy: 0.4964\n",
            "Epoch 9/10\n",
            "969/969 [==============================] - 6s 6ms/step - loss: 0.6932 - accuracy: 0.4977\n",
            "Epoch 10/10\n",
            "969/969 [==============================] - 7s 7ms/step - loss: 0.6932 - accuracy: 0.5021\n",
            "Epoch 1/10\n",
            "969/969 [==============================] - 59s 59ms/step - loss: 0.3061 - accuracy: 0.8792\n",
            "Epoch 2/10\n",
            "969/969 [==============================] - 56s 58ms/step - loss: 0.2309 - accuracy: 0.9275\n",
            "Epoch 3/10\n",
            "969/969 [==============================] - 66s 68ms/step - loss: 0.2244 - accuracy: 0.9287\n",
            "Epoch 4/10\n",
            "969/969 [==============================] - 55s 57ms/step - loss: 0.2220 - accuracy: 0.9276\n",
            "Epoch 5/10\n",
            "969/969 [==============================] - 55s 57ms/step - loss: 0.2143 - accuracy: 0.9285\n",
            "Epoch 6/10\n",
            "969/969 [==============================] - 56s 58ms/step - loss: 0.2078 - accuracy: 0.9286\n",
            "Epoch 7/10\n",
            "969/969 [==============================] - 57s 59ms/step - loss: 0.2066 - accuracy: 0.9289\n",
            "Epoch 8/10\n",
            "969/969 [==============================] - 54s 56ms/step - loss: 0.1993 - accuracy: 0.9301\n",
            "Epoch 9/10\n",
            "969/969 [==============================] - 55s 57ms/step - loss: 0.1985 - accuracy: 0.9314\n",
            "Epoch 10/10\n",
            "969/969 [==============================] - 55s 57ms/step - loss: 0.1942 - accuracy: 0.9317\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7ae12821ad40>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert sparse matrix to dense array\n",
        "X_resampled_test_dense = X_resampled_test.toarray()\n",
        "\n",
        "# Reshape the test data for CNN & RNN\n",
        "X_resampled_test_reshaped = X_resampled_test_dense.reshape((X_resampled_test_dense.shape[0], X_resampled_test_dense.shape[1], 1))\n",
        "\n",
        "# Predict using the CNN model\n",
        "y_pred_cnn = model_cnn.predict(X_resampled_test_reshaped)\n",
        "\n",
        "# Convert probabilities to binary predictions (0 or 1)\n",
        "y_pred_cnn_binary = (y_pred_cnn > 0.5).astype(int)\n",
        "\n",
        "# Calculate metrics for CNN model\n",
        "accuracy_cnn = accuracy_score(y_resampled_test, y_pred_cnn_binary)\n",
        "precision_cnn = precision_score(y_resampled_test, y_pred_cnn_binary)\n",
        "recall_cnn = recall_score(y_resampled_test, y_pred_cnn_binary)\n",
        "f1_cnn = f1_score(y_resampled_test, y_pred_cnn_binary)\n",
        "\n",
        "# Predict using the RNN model\n",
        "y_pred_rnn = model_rnn.predict(X_resampled_test_reshaped)\n",
        "\n",
        "# Convert probabilities to binary predictions (0 or 1)\n",
        "y_pred_rnn_binary = (y_pred_rnn > 0.5).astype(int)\n",
        "\n",
        "# Calculate metrics for RNN model\n",
        "accuracy_rnn = accuracy_score(y_resampled_test, y_pred_rnn_binary)\n",
        "precision_rnn = precision_score(y_resampled_test, y_pred_rnn_binary)\n",
        "recall_rnn = recall_score(y_resampled_test, y_pred_rnn_binary)\n",
        "f1_rnn = f1_score(y_resampled_test, y_pred_rnn_binary)\n",
        "\n",
        "# Print metrics for CNN model\n",
        "print(\"CNN Model Metrics:\")\n",
        "print(\"Accuracy:\", accuracy_cnn)\n",
        "\n",
        "# Print metrics for RNN model\n",
        "print(\"\\nRNN Model Metrics:\")\n",
        "print(\"Accuracy:\", accuracy_rnn)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T7UQ4qx4QckM",
        "outputId": "2625931c-fcb9-43a3-b39a-17fca930f806"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "971/971 [==============================] - 3s 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "971/971 [==============================] - 28s 28ms/step\n",
            "CNN Model Metrics:\n",
            "Accuracy: 0.5\n",
            "\n",
            "RNN Model Metrics:\n",
            "Accuracy: 0.8759173426033218\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fFZ_CO5iPGbO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}